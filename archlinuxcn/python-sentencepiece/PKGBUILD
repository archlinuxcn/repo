# Maintainer: Hu Butui <hot123tea123@gmail.com>

_name=sentencepiece
pkgname=python-sentencepiece
pkgver=0.2.0
pkgrel=7
pkgdesc="Unsupervised text tokenizer for Neural Network-based text generation"
arch=('x86_64')
url="https://github.com/google/sentencepiece"
license=('Apache-2.0')
depends=(
  gcc-libs
  glibc
  sentencepiece
  python
)
makedepends=(
  python-build
  python-installer
  python-setuptools
  python-wheel 
)
source=("${_name}-${pkgver}.tar.gz::https://github.com/google/sentencepiece/archive/refs/tags/v${pkgver}.tar.gz")
sha512sums=('b4214f5bfbe2a0757794c792e87e7c53fda7e65b2511b37fc757f280bf9287ba59b5d630801e17de6058f8292a3c6433211917324cb3446a212a51735402e614')

prepare() {
  sed -i 's/libsentencepiece.a/libsentencepiece.so/g' "${srcdir}/${_name}-${pkgver}/python/setup.py"
  sed -i 's/libsentencepiece_train.a/libsentencepiece_train.so/g' "${srcdir}/${_name}-${pkgver}/python/setup.py"
}


build() {
  cd "${_name}-${pkgver}/python"
  python -m build --wheel --no-isolation
}

package() {
  cd "${_name}-${pkgver}/python"
  python -m installer --destdir="${pkgdir}" dist/*.whl
}
# vim:set ts=2 sw=2 et:
