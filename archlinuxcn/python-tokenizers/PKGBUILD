# Maintainer: Butui Hu <hot123tea123@gmail.com>

_pkgname=tokenizers
pkgname=python-tokenizers
pkgver=0.11.2
pkgrel=1
pkgdesc='Fast State-of-the-Art Tokenizers optimized for Research and Production'
arch=('x86_64')
url='https://github.com/huggingface/tokenizers'
license=('Apache')
depends=(
  python
)
makedepends=(
  python-setuptools-rust
)

source=("${_pkgname}-${pkgver}.tar.gz::https://files.pythonhosted.org/packages/source/${_pkgname::1}/${_pkgname}/${_pkgname}-${pkgver}.tar.gz")
sha512sums=('df1202064d4ce0881006932f0d820223a5ad90bbe6f09844f768699073ee0b539a4d280999d571dfdf2566b275f5d4817e8888ac83f9ff299ac773024c9af9ee')

build() {
  cd "${_pkgname}-${pkgver}"
  python setup.py build
}

package() {
  cd "${_pkgname}-${pkgver}"
  python setup.py install --root="${pkgdir}" --optimize=1
}
# vim:set ts=2 sw=2 et:
